{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Storing data on the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Initialize S3 Bucket\n",
    "\n",
    "The S3 bucket will host our test_features data set which we can call in our lambda function to perform a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initizalize S3 Bucket:\n",
    "\n",
    "import boto3\n",
    "\n",
    "def create_bucket(region:str, bucket_name:str) -> dict:\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.create_bucket(\n",
    "        Bucket = bucket_name,\n",
    "        # CreateBucketConfiguration = {\n",
    "        #     'LocationConstraint':region\n",
    "        # }\n",
    "        # not needed when your region is default (us-east-1)\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "region = 'us-east-1'\n",
    "bucket_name = 'joaomj-lambda-buckets-2022'\n",
    "\n",
    "create_bucket(region, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Upload test data to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import joblib\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "def UploadToS3(data, bucket:str, key:str):\n",
    "\n",
    "    # Temporary store the dataset in a file object\n",
    "    # This file object will be uploaded onto a S3 bucket by calling the .upload_fileobj function\n",
    "    with BytesIO() as f:\n",
    "        joblib.dump(data, f) #\n",
    "        f.seek(0)\n",
    "        (\n",
    "            boto3\n",
    "            .client('s3')\n",
    "            .upload_fileobj(Bucket = bucket, Key = key, Fileobj = f)\n",
    "        )\n",
    "\n",
    "\n",
    "# loading dataset\n",
    "df_test = pd.read_csv('./app/test_dataset.csv')\n",
    "\n",
    "bucket_name = 'joaomj-lambda-buckets-2022'\n",
    "key = 'validation/df_test.joblib'\n",
    "\n",
    "UploadToS3(df_test, bucket_name, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. List objects in the S3 Bucket\n",
    "\n",
    "Check if the data was correctly stored in the S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def listS3objects(bucket:str) -> list:\n",
    "\n",
    "    # connect to S3 resource\n",
    "    s3 = boto3.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "\n",
    "    # list all object keys in S3 bucket\n",
    "    # obj_list = [object_summary.key for object_summary in my_bucket.objects.all()]\n",
    "\n",
    "    for object_summary in my_bucket.objects.all():\n",
    "        obj_list = [object_summary.key]\n",
    "\n",
    "    return obj_list\n",
    "\n",
    "print(listS3objects('joaomj-lambda-buckets-2022'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
